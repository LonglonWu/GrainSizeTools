# ============================================================================ #
#                                                                              #
#    GrainSizeTools Script                                                     #
#    A Python script for estimating grain size features from thin sections     #
#                                                                              #
#    Copyright (c) 2014-present   Marco A. Lopez-Sanchez                       #
#                                                                              #
#    Licensed under the Apache License, Version 2.0 (the "License");           #
#    you may not use this file except in compliance with the License.          #
#    You may obtain a copy of the License at                                   #
#                                                                              #
#        http://www.apache.org/licenses/LICENSE-2.0                            #
#                                                                              #
#    Unless required by applicable law or agreed to in writing, software       #
#    distributed under the License is distributed on an "AS IS" BASIS,         #
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  #
#    See the License for the specific language governing permissions and       #
#    limitations under the License.                                            #
#                                                                              #
#    Version 1.4.3                                                             #
#    For details see: http://marcoalopez.github.io/GrainSizeTools/             #
#    download at https://github.com/marcoalopez/GrainSizeTools/releases        #
#                                                                              #
#    Requirements:                                                             #
#        Python version 2.7.x, 3.5.x or higher                                 #
#        Numpy version 1.11 or higher                                          #
#        Matplotlib version 1.5.3 or higher                                    #
#        Scipy version 0.13 or higher                                          #
#        Pandas version 0.16.x or higher                                       #
#                                                                              #
# ============================================================================ #


from __future__ import division, print_function  # avoid python 2.x - 3.x compatibility issues
import os
import matplotlib.pyplot as plt
import numpy as np
from numpy import mean, std, median, pi, sqrt, exp, log, array, tan, arctan, delete
from pandas import read_table, read_csv, read_excel, DataFrame
from scipy.stats import gaussian_kde, iqr
from scipy.optimize import curve_fit

# Set the plot style. To see the different styles available in Matplotlib see:
# https://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html
import matplotlib as mpl
mpl.style.use('ggplot')
mpl.rcParams['font.family'] = 'Helvetica Neue'  # define here the font you like in the plots
mpl.rcParams['xtick.labelsize'] = 11.
mpl.rcParams['ytick.labelsize'] = 11.


def extract_areas(file_path='auto', col_name='Area'):
    """ Extract the data corresponding to the areas of grain profiles from
    tabular-like text files generated by the ImageJ or similar applications.
    Files can be in plain text (.txt, .csv) or excel (.xlsx) format

    Parameters
    ----------
    file_path: string
        the file location in quotes
        e.g: 'C:/...yourFileLocation.../nameOfTheFile.csv'
        If 'auto' the function will ask you for the location of the file
        through a file selection dialog.

    col_name: string
        the name of the column that contains the areas of the grain profiles.
        'Area' by default.
    """

    if file_path == 'auto':
        try:  # code for Python 3.x versions
            import tkinter as tk
            from tkinter import filedialog
            root = tk.Tk()
            root.withdraw()
            root.attributes("-topmost", True)
            file_path = filedialog.askopenfilename(initialdir=os.getcwd(),
                                                   title="Select file",
                                                   filetypes=[('Text files', '*.txt'),
                                                              ('Text files', '*.csv')])
        except ImportError:  # code for Python 2.7.x versions
            import Tkinter as tk
            import tkFileDialog
            root = tk.Tk()
            root.withdraw()
            root.attributes("-topmost", True)
            file_path = tkFileDialog.askopenfilename(initialdir=os.getcwd(),
                                                     title="Select file",
                                                     filetypes=[('Text files', '*.txt'),
                                                                ('Text files', '*.csv')])
    if file_path.endswith('.txt'):
        data_frame = read_table(file_path)
        data_set = array(data_frame[col_name])

    elif file_path.endswith('.csv'):
        data_frame = read_csv(file_path)
        data_set = array(data_frame[col_name])

    elif file_path.endswith('.xlsx'):
        data_frame = read_excel(file_path)
        data_set = array(data_frame[col_name])

    else:
        print("Error: The file is not a 'txt' nor 'csv' or 'xlsx' or the file extension was not specified.")
        return None

    print(' ')
    print(data_frame.head())
    print('...')
    print(data_frame.tail())
    print(' ')
    print('column extracted =', data_set)
    print('n =', len(data_set))
    print(' ')

    return data_set


def calc_diameters(areas, correct_diameter=0):
    """ Calculate the diameters from the sectional areas via the equivalent circular
    diameter.

    Parameters
    ----------
    areas: array_like
        the sectional areas of the grains

    correct_diameter: positive integer or float
        this adds the width of the grain boundaries to correct the diameters. If
        correct_diameter is not declared no correction is considered.

    Returns
    -------
    A numpy array with the equivalent circular diameters
    """

    # calculate diameters via equivalent circular diameter
    diameters = 2 * sqrt(areas / pi)

    # diameter correction adding edges (if applicable)
    if correct_diameter != 0:
        diameters += correct_diameter

    return diameters


def find_grain_size(areas, diameters, plot='lin', binsize='auto'):
    """ Estimate different 1D measures of grain size from a population
    of apparent diameters and their areas. It includes the mean,
    area-weighted mean, median, and frequency peak grain sizes.

    Parameters
    ----------
    areas: array_like
        the areas of the grain profiles

    diameters: array_like
        the apparent diameters of the grains

    plot: string
        the scale/type of the plot and grain size estimation.

        | Types:
        | 'lin' for a linear frequency vs diameter
        | 'log' for a frequency vs logarithmic diameter
        | 'sqrt' for a frequency vs square root diameter
        | 'area' for a area-weighted frequency vs diameter.

    binsize: string, or positive integer or float
        If 'auto', it defines the plug-in method to calculate the bin size.
        When integer or float, it directly specifies the bin size.
        Default: the 'auto' method.

        | Available plug-in methods:
        | 'auto' (fd if sample_size > 1000 or Sturges otherwise)
        | 'doane' (Doane's rule)
        | 'fd' (Freedman-Diaconis rule)
        | 'rice' (Rice's rule)
        | 'scott' (Scott rule)
        | 'sqrt' (square-root rule)
        | 'sturges' (Sturge's rule)

    Call functions
    --------------
    - calc_freq_grainsize
    - calc_areaweighted_grainsize

    Returns
    -------
    A plot with the distribution of apparent grain sizes and several statistical
    parameters
    """

    # determine the grain size parameters using a number-weighted approach
    if plot == 'lin':
        return calc_freq_grainsize(diameters, binsize, plot='linear')

    elif plot == 'log':
        diameters = log(diameters)
        return calc_freq_grainsize(diameters, binsize, plot='log')

    elif plot == 'sqrt':
        diameters = sqrt(diameters)
        return calc_freq_grainsize(diameters, binsize, plot='sqrt')

    # determine the grain size using the area-weighted approach
    elif plot == 'area':
        return calc_areaweighted_grainsize(areas, diameters, binsize)

    else:
        print("Error: the type of plot was not defined as 'lin', 'log', 'sqrt' or 'area'. Try again.")
        return None


def derive3D(diameters, numbins=10, set_limit=None, fit=False, initial_guess=False):
    """ Estimates the actual (3D) distribution of grain size from the population of
    apparent diameters measured in a thin section using two approaches:

    i) the Saltykov method (Saltykov 1967; Sahagian and Proussevitch 1998)
    ii) the two-step method (Lopez-Sanchez and Llana-Funez, 2016).

    The Saltykov method is optimal to estimate the volume of a particular grain size
    fraction as well as to obtain a qualitative view of the appearance of the actual
    3D grain size population, either in uni- or multimodal populations.

    The two-step method is aimed at estimating quantitatively the shape of the
    actual 3D distribution of grain sizes. The method only works properly for
    unimodal lognormal-like grain size populations and returns the MSD (i.e. shape)
    and the median (i.e. scale) values, which describe the lognormal population of
    grain sizes at their lineal scale. For details see Lopez-Sanchez and Llana-Funez (2016).

    References
    ----------
    | Saltykov SA (1967) http://doi.org/10.1007/978-3-642-88260-9_31
    | Sahagian and Proussevitch (1998) https://doi.org/10.1016/S0377-0273(98)00043-2
    | Lopez-Sanchez and Llana-Funez (2016) https://doi.org/10.1016/j.jsg.2016.10.008

    Parameters
    ----------
    diameters: array_like
        the apparent diameters of the grains

    numbins: integer (positive)
        the number of bins/classes of the histrogram. If not declared, is set
        to 10 by default

    set_limit: integer, float (positive) or None
        if the user specifies a number, the function will return the volume
        occupied by the grain fraction up to that value.

    fit: boolean
        if False, the standard Saltykov method is applied. If True, the two-step
        method is applied.

    initial_guess: boolean
        If False, the script will use the default guessing values to fit a
        lognormal distribution. If True, the script will ask the user to define
        their own MSD and median guessing values.

    Call functions
    --------------
    - Saltykov
    - Saltykov_plot
    - gen_xgrid
    - fit_function
    - twostep_plot

    Returns
    -------
    A plot with an estimate of the actual (3D) grains size distribution and
    several statistical parameters
    """

    # check if numbins is a positive integer
    if isinstance(numbins, int) is False:
        print(' ')
        print('Error: numbins must be an integer')
        return None

    if numbins <= 0:
        print(' ')
        print('Error: numbins must be a positive integer')
        return None

    # compute the histogram
    freq, bin_edges = np.histogram(diameters, bins=numbins, range=(0., max(diameters)), density=True)
    binsize = bin_edges[1]
    print(' ')
    print('sample size =', len(diameters))
    print('bin size =', round(binsize, 2))
    print(' ')

    # Create an array with the left edges of the bins and other with the midpoints
    left_edges = delete(bin_edges, -1)
    mid_points = left_edges + binsize / 2.

    # Applied the Scheil-Schwartz-Saltykov method to unfold the population of apparent diameters
    freq3D = Saltykov(freq, bin_edges, binsize, mid_points)

    # Calculates the volume-weighted cumulative frequency distribution
    x_vol = binsize * (4 / 3.) * pi * (mid_points**3)
    freq_vol = x_vol * freq3D
    cdf = np.cumsum(freq_vol)
    cdf_norm = 100 * (cdf / cdf[-1])

    if fit is False:
        if set_limit is not None:
            x = mid_points
            y = cdf_norm
            index = np.argmax(mid_points > set_limit)
            angle = arctan((y[index] - y[index - 1]) / (x[index] - x[index - 1]))
            volume = y[index - 1] + tan(angle) * (set_limit - x[index - 1])
            if volume < 100.0:
                print('volume fraction (up to', set_limit, 'microns) =', round(volume, 2), '%')
                print(' ')
            else:
                print('volume fraction (up to', set_limit, 'microns) =', 100, '%')
                print(' ')

        # Generate the plot
        Saltykov_plot(left_edges, freq3D, binsize, mid_points, cdf_norm)

        # Save a text file with the midpoints, class frequencies, and cumulative volumes
        df = DataFrame({'mid_points': np.around(mid_points, 3), 'freqs': np.around(freq3D, 4), 'cum_vol': np.around(cdf_norm, 2)})
        print('A file named Saltykov_output.csv containing the midpoints, class frequencies, \nand cumulative volumes was generated')

        return df.to_csv('Saltykov_output.csv', sep='\t')

    # Fit a lognormal distribution with uncertainties to 3D data
    elif fit is True:
        if initial_guess is False:
            shape = 1.2
            scale = 25.0
        elif initial_guess is True:
            shape = float(input('Define an initial guess for the MSD parameter (the default value is 1.2; MSD > 1.0): '))
            scale = float(input('Define an initial guess for the median parameter (the default value is 25.0; median > 0.0 ): '))
        else:
            print('initial_guess was not set as True nor False. The default guessing values will be used')
            shape = 1.2
            scale = 25.0

        # optp = OPTimal Parameters for fit; covm = COVariance Matrix
        optp, covm = curve_fit(fit_function, mid_points, freq3D, [shape, scale])

        # estimate the uncertainty of the fit. We use the square root of the
        # diagonal values within the covariance matrix, which are the standard
        # deviations
        sigma_err = sqrt([covm[0, 0], covm[1, 1]])

        print('Optimal coefficients:')
        print('MSD (shape) =', round(optp[0], 2), '±', round(3 * sigma_err[0], 2))
        print('Median (location) =', round(optp[1], 2), '±', round(3 * sigma_err[1], 2), '(caution: not fully realiable)')
        print(' ')
        # print(' Covariance matrix:\n', covm)

        # Generate a mesh of x-values
        xgrid = gen_xgrid(diameters, 0.1, max(diameters))

        # Calculate the curve of the best fit
        best_fit = fit_function(xgrid, optp[0], optp[1])

        # Estimate all the combinatorial posibilities for fit curves taking into account the uncertainties
        values = array([fit_function(xgrid, optp[0] + sigma_err[0], optp[1] + sigma_err[1]),
                        fit_function(xgrid, optp[0] - sigma_err[0], optp[1] - sigma_err[1]),
                        fit_function(xgrid, optp[0] + sigma_err[0], optp[1] - sigma_err[1]),
                        fit_function(xgrid, optp[0] - sigma_err[0], optp[1] + sigma_err[1])])

        # Estimate the standard deviation of the all values obtained
        # I use this approach instead of getting the min a max values obtained
        fit_error = std(values, axis=0)

        # Generate the plot
        twostep_plot(left_edges, freq3D, binsize, mid_points, freq3D, xgrid, best_fit, fit_error)

        # Save a text file with the midpoints and class frequencies
        df = DataFrame({'mid_points': np.around(mid_points, 3), 'freqs': np.around(freq3D, 4)})
        print('A file named twoStep_output.csv containing the midpoints and class frequencies \nwas generated')
        return df.to_csv('twoStep_output.csv', sep='\t')

    else:
        print('fit parameter was not defined as True nor False. Please try again.')
        return None


def quartz_piezometer(grain_size, piezometer='Stipp_Tullis'):
    """ Apply different quartz piezometric relations to estimate the differential
    stress from 1D apparent grain sizes. The piezometric relations has the
    following expression:

    diff_stress = B * grain_size**-m

    where diff_stress is the differential stress in [MPa], B is an experimentally
    derived parameter in [MPa micron**m], grain_size is the aparent grain size
    in [microns], and m is an experimentally derived exponent which is adimensonal.

    Parameters
    ----------
    grain_size: positive integer or float
        the apparent grain size in microns

    piezometer: string
        the piezometric relation, either:
            | 'Cross' and 'Cross_hr' from Cross et al. (2017)
            | 'Holyoke' and 'Holyoke_BLG' from Holyoke and Kronenberg (2010)
            | 'Shimizu' from Shimizu (2008)
            | 'Stipp_Tullis' and 'Stipp_Tullis_BLG' from Stipp and Tullis (2003)
            | 'Twiss' from Twiss (1977)

    References
    ----------
    | Cross et al. (2017) https://doi.org/10.1002/2017GL073836
    | De Hoff and Rhines (1968) Quantitative Microscopy. Mcgraw-Hill. New York.
    | Holyoke and Kronenberg (2010) https://doi.org/10.1016/j.tecto.2010.08.001
    | Shimizu (2008) https://doi.org/10.1016/j.jsg.2008.03.004
    | Stipp and Tullis (2003)  https://doi.org/10.1029/2003GL018444
    | Twiss (1977) https://www.doi.org/10.1007/BF01637105

    Assumptions
    -----------
    - Independence of temperature (excepting Shimizu piezometer), total strain,
    flow stress, and water content.

    - Recrystallized grains are equidimensional or close to equidimensional when
    using a single section.

    - The piezometer relations of Stipp and Tullis (2003), Holyoke and Kronenberg
    (2010) and Cross et al. (2007) requires entering the grain size as the square
    root mean apparent grain size calculated using equivalent circular diameters
    with no stereological correction.

    - The piezometer relation of Shimizu (2008) requires entering the grain size
    as the logarithmic median apparent grain size calculated using equivalent
    circular diameters with no stereological correction.

    - The piezometer of Twiss (1977) requires entering the logarithmic mean apparent
    grain size calculated from equivalent circular diameters (ECD) with no stereological
    correction. The function will convert this value to mean linear intercept (LI)
    grain size using the De Hoff and Rhines (1968) empirical relation and assuming
    that LI was originally multiplied by 1.5 (correction factor). Then the final
    relation is: LI = (1.5 / sqrt(4/pi)) * ECD

    Returns
    -------
    The differential stress in MPa, a floating point number
    """

    if piezometer == 'Stipp_Tullis':
        B = 669.0
        m = 0.79
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'Stipp_Tullis_BLG':
        B = 1264.1
        m = 1.64
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'Holyoke':
        B = 490.3
        m = 0.79
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'Holyoke_BLG':
        B = 883.9
        m = 1.85
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'Cross':
        B = 593.0
        m = 0.71
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'Cross_hr':
        B = 450.9
        m = 0.63
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'Shimizu':
        B = 352
        m = 0.8
        T = float(input("Shimizu's paleopiezometer requires setting the temperature [in K] during deformation: "))
        print('Ensure that you entered the apparent grain size as the log median!')

        diff_stress = 352 * grain_size**(-m) * exp(698 / T)

        print(' ')
        print('differential stress =', round(diff_stress, 2), 'MPa')
        return None

    elif piezometer == 'Twiss':
        B = 5.5  # this B value is for grain size in mm (Twiss, 1977)
        m = 0.68
        grain_size = grain_size / 1000  # convert from microns to mm
        grain_size = (1.5 / (np.sqrt(4 / np.pi))) * grain_size  # convert ECD to LI
        print('Ensure that you entered the apparent grain size as the log mean!')

    else:
        print(' ')
        print('Wrong name. Please choose between valid piezometers')
        return None

    diff_stress = B * grain_size**-m

    print(' ')
    print('differential stress =', round(diff_stress, 2), 'MPa')
    return None


def olivine_piezometer(grain_size, piezometer='Jung_Karato'):
    """ Apply different olivine piezometric relations to estimate the differential
    stress from 1D apparent grain sizes. The piezometric relations has the
    following expression:

    diff_stress = B * grain_size**-m

    where diff_stress is the differential stress in [MPa], B is an experimentally
    derived parameter in [MPa micron**m], grain_size is the aparent grain size
    in [microns], and m is an experimentally derived exponent which is adimensonal.

    Parameters
    ----------
    grain_size: positive integer or float
        the apparent grain size in microns

    piezometer: string
        the piezometric relation, either:
            | 'VanderWal_wet' from Van der Wal et al. (1993)
            | 'Jung_Karato' from Jung and Karato (2001)

    References
    ----------
    | Jung and Karato (2001) https://doi.org/10.1016/S0191-8141(01)00005-0
    | Van der Wal et al. (1993) https://doi.org/10.1029/93GL01382

    Assumptions
    -----------
    - Independence of temperature, total strain, flow stress, and water content.

    - The piezometer of Van der Wal (1993) requires entering the linear mean apparent
    grain size in microns calculated from equivalent circular diameters (ECD) with no
    stereological correction. The function will convert automatically this value to
    linear intercept (LI) grain size using the De Hoff and Rhines (1968) empirical
    equation. Since LI was originally multiplied by 1.2 (correction factor),
    the final relation is: LI = (1.2 / sqrt(4/pi)) * ECD

    - The piezometer of Jung and Karato (2001) requires entering the linear mean
    apparent grain size in microns calculated from equivalent circular diameters
    (ECD) with no stereological correction. The function will convert automatically
    this value to linear intercept (LI) grain size using the De Hoff and Rhines
    (1968) empirical equation. Since LI was originally multiplied by 1.5 (correction
    factor), the final relation is: LI = (1.5 / sqrt(4/pi)) * ECD

    Returns
    -------
    The differential stress in MPa, a floating point number
    """

    if piezometer == 'Jung_Karato':
        B = 5461.03
        m = 0.85
        grain_size = (1.5 / (np.sqrt(4 / np.pi))) * grain_size  # convert ECD to LI
        print('Ensure that you entered the apparent grain size as the linear scale mean!')

    elif piezometer == 'VanderWal_wet':
        B = 0.0425  # this B value requires average grain size in m
        m = 0.75
        grain_size = grain_size / 1e6  # convert from microns to m
        grain_size = (1.2 / (np.sqrt(4 / np.pi))) * grain_size  # convert ECD to LI
        print('Ensure that you entered the apparent grain size as the linear scale mean!')

    else:
        print('Wrong name. Please choose between valid piezometers')
        return None

    diff_stress = B * grain_size**-m

    print(' ')
    print('differential stress =', round(diff_stress, 2), 'MPa')
    return None


def other_piezometers(grain_size, piezometer='calcite_Rutter_SGR'):
    """ Apply different piezometric relations to estimate the differential
    stress from 1D apparent grain sizes. The piezometric relations has the
    following expression:

    diff_stress = B * grain_size**-m

    where diff_stress is the differential stress in [MPa], B is an experimentally
    derived parameter in [MPa micron**m], grain_size is the aparent grain size
    in [microns], and m is an experimentally derived exponent which is adimensonal.

    Parameters
    ----------
    grain_size: positive integer or float
        the apparent grain size in microns

    piezometer: string
        the piezometric relation, either:
            | 'calcite_Rutter_SGR' from Rutter (1995)
            | 'calcite_Rutter_GBM' from Rutter (1995)
            | 'albite_PostT_BLG' from Alice and Post (1999)
            | More pizometers soon!


    References
    ----------
    | Alice and Post (1999) https://doi.org/10.1016/S0040-1951(98)00260-1
    | Rutter (1995) https://doi.org/10.1029/95JB02500

    Assumptions
    -----------
    - Independence of temperature, total strain, flow stress, and water content.

    - Recrystallized grains are equidimensional or close to equidimensional when
    using a single section.

    - The piezometer relation of Rutter (1995) requires entering the grain size
    as the root square mean apparent grain size calculated using equivalent
    circular diameters with no stereological correction.

    - The piezometer of Post and Tullis (1999) requires entering the median
    apparent grain size calculated from equivalent circular diameters (ECD) with
    no stereological correction. The function will convert this value to the mean
    linear intercept (LI) grain size using the De Hoff and Rhines (1968) empirical
    relation LI = ECD / sqrt(4/pi)

    Returns
    -------
    The differential stress in MPa, a floating point number
    """

    if piezometer == 'calcite_Rutter_SGR':
        B = 812.83
        m = 0.88
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'calcite_Rutter_GBM':
        B = 2691.53
        m = 0.89
        print('Ensure that you entered the apparent grain size as the square root mean!')

    elif piezometer == 'albite_PostT_BLG':
        B = 433.4
        m = 1.52
        grain_size = grain_size / np.sqrt(4 / np.pi)  # convert ECD to LI
        print('Ensure that you entered the apparent grain size as the linear scale median!')

    else:
        print('Wrong name. Please choose between valid piezometers')
        return None

    diff_stress = B * grain_size**-m

    print(' ')
    print('differential stress =', round(diff_stress, 2), 'MPa')
    return None


# ============================================================================ #
# Functions used by the find_grain_size and the derive3D functions to generate #
# the plots using the matplotlib library. I use hex color codes to set colors. #
# ============================================================================ #


def freq_plot(diameters, binList, xgrid, y_values, y_max, x_peak, mean_GS, median_GS, plot='freq'):
    """ Generate a frequency vs grain size plot"""

    fig, ax = plt.subplots()

    ax.hist(diameters,
            bins=binList,
            range=(0, diameters.max()),
            density=True,
            color='#108ed2',
            edgecolor='#e7f6fd')
    ax.plot([mean_GS, mean_GS], [0.0001, y_max],
            linestyle='-',
            color='#1F1F1F',
            label='mean',
            linewidth=2)
    ax.plot([median_GS, median_GS], [0.0001, y_max],
            linestyle='--',
            color='#1F1F1F',
            label='median',
            linewidth=2)
    ax.plot(xgrid, y_values,
            color='#1F1F1F',
            linewidth=2)

    ax.set_ylabel('frequency',
                  fontsize=13)

    if plot == 'freq':
        ax.set_xlabel(r'apparent diameter ($\mu m$)',
                      fontsize=13)

    elif plot == 'log':
        ax.set_xlabel(r'apparent diameter ln ($\mu m$)',
                      fontsize=13)

    elif plot == 'sqrt':
        ax.set_xlabel(r'apparent diameter sqrt ($\mu m$)',
                      fontsize=13)

    ax.plot([x_peak], [y_max],
            'o',
            color='#1F1F1F',
            label='freq. peak')
    ax.vlines(x_peak, 0.0001, y_max,
              linestyle=':',
              color='#1F1F1F',
              linewidth=2)
    ax.annotate('Gaussian KDE peak',
                xy=(x_peak, y_max),
                xytext=(+10, +30),
                label='peak')
    ax.legend(loc='upper right',
              fontsize=11)

    fig.tight_layout()

    return plt.show()


def area_weighted_plot(intValues, cumulativeAreas, h, weightedMean):
    """ Generate the area-weighted frequency vs grain size plot"""

    # first normalize the y-axis values to percentage of the total area
    totalArea = sum(cumulativeAreas)
    cumulativeAreasNorm = [(x / float(totalArea)) * 100 for x in cumulativeAreas]
    maxValue = max(cumulativeAreasNorm)

    fig, ax = plt.subplots()

    # figure aesthetics
    ax.bar(intValues, cumulativeAreasNorm, width=h,
           color='#0faeb9',
           edgecolor='#e7fcfd',
           align='edge')
    ax.plot([weightedMean, weightedMean], [0.0001, maxValue],
            linestyle='--',
            color='#1F1F1F',
            label='area weighted mean',
            linewidth=2)
    ax.set_ylabel('% of area fraction',
                  fontsize=13)
    ax.set_xlabel(r'apparent diameter ($\mu m$)',
                  fontsize=13)
    ax.legend(loc='upper right',
              fontsize=11)

    fig.tight_layout()

    return plt.show()


def Saltykov_plot(left_edges, freq3D, binsize, mid_points, cdf_norm):
    """ Generate two plots once the Saltykov method is applied:

    i)  a frequency plot (ax1)
    ii) a volume-weighted cumulative frequency plot (ax2)
    """

    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))

    ax1.bar(left_edges, freq3D, width=binsize,
            color='#108ED2',
            edgecolor='#e7f6fd',
            align='edge')
    ax1.set_ylabel('frequency',
                   fontsize=13)
    ax1.set_xlabel(r'diameter ($\mu m$)',
                   fontsize=13)
    ax1.set_title('estimated 3D grain size distribution',
                  color='#1F1F1F',
                  fontsize=13.5,
                  y=1.02)

    ax2.set_ylim([-2, 105])
    ax2.plot(mid_points, cdf_norm,
             'o-',
             color='#ed4256',
             label='volume weighted CFD',
             linewidth=2)
    ax2.set_ylabel('cumulative volume (%)',
                   fontsize=13)
    ax2.set_xlabel(r'diameter ($\mu m$)',
                   fontsize=13)
    ax2.set_title('volume-weighted cumulative freq. distribution',
                  color='#1F1F1F',
                  fontsize=13.5,
                  y=1.02)

    fig.tight_layout()

    return plt.show()


def twostep_plot(left_edges, freq3D, binsize, mid_points_corrected, freq3D_corrected, xgrid, best_fit, fit_error):
    """ Generate a plot with the best fitting lognormal distribution (two-step method)"""

    fig, ax = plt.subplots()

    # bar plot from Saltykov method
    ax.bar(left_edges, freq3D,
           width=binsize,
           edgecolor='#1F1F1F',
           hatch='//',
           color='#fff2ae',
           fill=False,
           linewidth=1,
           label='Saltykov method',
           align='edge',
           alpha=0.65)

    # plot log-normal distribution
    ax.plot(xgrid, best_fit,
            color='#1F1F1F',
            label='best fit',
            linewidth=2)
    ax.fill_between(xgrid, best_fit + (3 * fit_error), best_fit - (3 * fit_error),
                    color='#525252',
                    label='trust region',
                    alpha=0.5)
    ax.plot(mid_points_corrected, freq3D_corrected,  # datapoints used for the fitting procedure
            'o',
            color='#d53e4f',
            label='datapoints',
            linewidth=1.5)

    ax.set_ylabel('freq. (per unit vol.)',
                  fontsize=13)
    ax.legend(loc='upper right',
              fontsize=11)
    ax.set_xlabel(r'diameter ($\mu m$)',
                  fontsize=13)

    fig.tight_layout()

    return plt.show()


# ============================================================================== #
# functions used by the find_grain_size and the derive3D functions to obtain all #
# the parameters needed to estimate the grain size and generate the plots. The   #
# names of the functions are self-explanatory.                                   #
# ============================================================================== #

def calc_freq_grainsize(diameters, binsize, plot):
    """ Calculate the distribution of grain sizes using the histogram and Gaussian
    kernel density estimator (KDE). It returns the modal interval, the middle value
    of modal interval, and the frequency peak based on the KDE, and call the
    function responsible for generating the corresponding plot.

    Parameters
    ----------
    diameters: array_like
        the diameters of the grains

    binsize: string (rule of thumb), integer, or float
        the bin size

    plot: string
        the type of plot and grain size, either 'linear', 'log' or 'sqrt'.

    Call function
    -------------
    - freq_plot
    """

    if len(diameters) < 433:
        print(' ')
        print('Caution! You should use more than 433 grain measurements for reliable results')

    mean_GS = mean(diameters)
    std_GS = std(diameters)
    median_GS = median(diameters)
    iqr_GS = iqr(diameters)

    # estimate the number of classes using an automatic plug-in method (if apply)
    if type(binsize) is str:
        histogram, bin_edges = np.histogram(diameters, bins=binsize, range=(0.0, diameters.max()))
        h = bin_edges[1]

    else:
        bin_edges = np.arange(0.0, diameters.max() + binsize, binsize)
        h = binsize
        histogram, bin_edges = np.histogram(diameters, bins=bin_edges)

    # find the grain size range in which the histogram value is the maximum
    index = np.argmax(histogram)  # see numpy argmax for details
    modInt_leftEdge = bin_edges[index]
    modInt_rightEdge = modInt_leftEdge + h

    # calculate the Gaussian kernel density function
    # the bandwidth selection is based on the Silverman rule (Silverman 1986)
    kde = gaussian_kde(diameters, bw_method=my_kde_bandwidth)

    # determine where the Gaussian kde function reach it maximum value
    xgrid = gen_xgrid(diameters, diameters.min(), diameters.max())
    y_values = kde(xgrid)  # find y-values using the gaussian kde function
    y_max, index = np.max(y_values), np.argmax(y_values)  # get maximum value and the index
    x_peak = xgrid[index]  # get the diameter (x-value) where y-value is maximum

    print(' ')
    print('NUMBER WEIGHTED APPROACH with', plot, 'apparent grain size:')
    print(' ')
    print('Mean grain size =', round(mean_GS, 2), 'microns')
    print('Standard deviation =', round(std_GS, 2), '(1-sigma)')
    print('Median grain size =', round(median_GS, 2), 'microns')
    print('Interquartile range (IQR) =', round(iqr_GS, 2))
    print(' ')
    print('HISTOGRAM FEATURES')
    print('The modal interval is', round(modInt_leftEdge, 2), '-', round(modInt_rightEdge, 2))
    print('The number of classes are', len(histogram))
    if type(binsize) is str:
        print('The bin size is', round(h, 2), 'according to the', binsize, 'rule')
    print(' ')
    print('GAUSSIAN KERNEL DENSITY ESTIMATOR FEATURES')
    print('KDE peak (peak grain size) = ', round(x_peak, 2), 'microns')
    print('Bandwidth =', round(kde.covariance_factor() * diameters.std(ddof=1), 2), '(Silverman rule)')
    print(' ')

    return freq_plot(diameters, bin_edges, xgrid, y_values, y_max, x_peak, mean_GS, median_GS)


def gen_xgrid(pop, start, stop):
    """ Returns a mesh of values.

    Parameters
    ----------
    pop: array_like
        the population
    start: integer or float (positive)
        the starting value of the sequence
    stop: integer or float (positive)
        the end value of the sequence
    """

    d_range = pop.max() - pop.min()

    if d_range < 400:
        density = 2**12
    else:
        density = 2**14

    return np.linspace(start, stop, density)


def my_kde_bandwidth(obj, fac=1.):
    """ Returns the Silverman bandwidth multiplied by a constant factor
    if neccesary.

    Parameters
    ----------
    obj:
        the kde object
    fac: integer or float (positive)
        the constant factor, 1.0 as default

    Returns
    -------
    The bandwidth of the Gaussian kde. A float.
    """

    bandwidth = np.power(obj.n * (obj.d + 2.0) / 4.0, -1. / (obj.d + 4)) * fac

    return bandwidth


def calc_areaweighted_grainsize(areas, diameters, binsize):
    """ Calculates the area percentage of each grain size interval. It is
    based on Herwegh (2000) and Berger et al. (2011) approach. Returns the
    the grain size interval with the maximum area accumulated, the middle
    value of this interval and the area weighted arithmetic mean.

    References
    ----------
    | Herwegh (2000) doi:10.1016/S0191-8141(99)00165-0
    | Berger et al. (2011) doi:10.1016/j.jsg.2011.07.002

    Parameters
    ----------
    areas: array_like
        a list with the sectional areas of the grains

    diameters: array_like
        a list with the equivalent circular diameters of the grains

    binsize: a string (plug-in methods), integer, or float
        the bin size
    """

    # calculate the area weighted arithmetic mean
    areatotal = float(sum(areas))
    weightedAreas = areas / areatotal
    weigtedDiameters = diameters * weightedAreas
    weightedMean = sum(weigtedDiameters)

    # estimate the bin size using an automatic plug-in method (if apply)
    if type(binsize) is str:
        histogram, bin_edges = np.histogram(diameters, bins=binsize, range=(0.0, diameters.max()))
        h = bin_edges[1]

    else:
        bin_edges = np.arange(0.0, diameters.max() + binsize, binsize)
        h = binsize

    cumulativeAreas = []  # Initialize variable

    # estimate the cumulative areas of each grain size interval
    for values in bin_edges:
        mask = np.logical_and(diameters >= values, diameters < (values + h))
        area_sum = np.sum(areas[mask])
        cumulativeAreas.append(round(area_sum, 1))

    # get the index of the maximum value (the modal interval)
    getIndex = cumulativeAreas.index(max(cumulativeAreas))
    print(' ')
    print('AREA WEIGHTED APPROACH:')
    print(' ')
    print('Area-weighted mean grain size =', round(weightedMean, 2), 'microns')
    print(' ')
    print('HISTOGRAM FEATURES')
    print('The modal interval is', round(bin_edges[getIndex], 2), '-', round(bin_edges[getIndex] + h, 2), 'microns')
    print('Midpoint (of modal interval) =', round((bin_edges[getIndex] + (bin_edges[getIndex] + h)) / 2.0, 1), 'microns')
    print('The number of classes are', len(cumulativeAreas) - 1)
    if type(binsize) is str:
        print('The bin size is', round(h, 2),
              'according to the', binsize, 'rule')
    print(' ')

    return area_weighted_plot(bin_edges, cumulativeAreas, h, weightedMean)


def wicksell_eq(D, d1, d2):
    """ This is the equation that calculates the cross-section size probability
    for a population of spheres based on Wicksell (1925) and later used by
    Scheil (1931), Schwartz (1934) and Saltykov (1967) to develop the Scheil-
    Schwartz-Saltykov method. This is the generalization by Sahagian and
    Proussevitch (1998):

    P(r1<r<r2) = 1/R * (sqrt(R^2-r1^2) - sqrt(R^2-r2^2))

    where R is the sphere radius and r the cross-section radius. Specifically r1
    and r2 are the lower and upper bounds of the bin, respectively.

    References
    ----------
    | Sahagian and Proussevitch (1998) doi:10.1029/95JB02500
    | Saltykov (1967) doi:10.1007/978-3-642-88260-9_31
    | Scheil (1931) doi:10.1002/zaac.19312010123
    | Schwartz (1934) Met. Alloy 5:139
    | Wicksell (1925) doi:10.2307/2332027
    | Higgins (2000) doi:10.2138/am-2000-8-901

    Parameters
    ----------
    D: positive integer or float
        the midpoint of the actual class, which corresponds with the diameter

    d1: positive integer or float
        the lower limit of the bin/class

    d2: positive integer or float
        the upper limit of the bin/class
    """

    # convert diameters to radii
    R = D / 2.0
    r1 = d1 / 2.0
    r2 = d2 / 2.0

    return 1 / R * (sqrt(R**2 - r1**2) - sqrt(R**2 - r2**2))


def Saltykov(freq, bin_edges, binsize, mid_points, normalize=True):
    """ Applies the Scheil-Schwartz-Saltykov method to unfold the population of
    apparent (2D) diameters into the actual (3D) population of grain sizes.
    Following the reasoning of Higgins (2000), R (or D) is placed at the center
    of the classes (i.e. the midpoints).

    Reference
    ----------
    Higgins (2000) doi:10.2138/am-2000-8-901

    Parameters
    ----------
    freq: array_like
        a list with the frequency of the different classes

    bin_edges: array_like
        a list with the edges of the classes

    mid_points: array_like
        a list with the midpoints of the classes

    normalize: boolean
        when True negative values of frequency are set to zero and then
        the distribution normalized. It is True by default.

    Returns
    -------
    The normalized frequencies of the unfolded population such that the integral
    over the range is one
    """

    d_values = np.copy(bin_edges)
    midpoints = np.copy(mid_points)
    i = len(midpoints) - 1

    while i > 0:
        j = i
        D = d_values[-1]
        Pi = wicksell_eq(D, d_values[i], d_values[i + 1])

        if freq[i] > 0:
            while j > 0:
                D = midpoints[-1]
                Pj = wicksell_eq(D, d_values[j - 1], d_values[j])
                P_norm = (Pj * freq[i]) / Pi
                np.put(freq, j - 1, freq[j - 1] - P_norm)  # replace specified elements of an array
                j -= 1

            i -= 1
            d_values = delete(d_values, -1)
            midpoints = delete(midpoints, -1)

        # if the value of the current class is zero or negative move to the next class
        else:
            i -= 1
            d_values = delete(d_values, -1)
            midpoints = delete(midpoints, -1)

    if normalize is True:
        freq = np.clip(freq, 0., 2**20)  # replacing negative values with zero
        freq_norm = freq / sum(freq)  # normalize to one
        freq_norm = freq_norm / binsize  # normalize such that the integral over the range is one
        return freq_norm

    else:
        return freq


def fit_function(x, shape, scale):
    """ Defines a custom function to fit the data using the scipy curve_fit routine.
    In this case, it is the two-parameter equation that describes a lognormal
    distribution using the mean and the standard deviation of the log(x) with base e.

    Parameters
    ----------
    x: array_like
        the x-values

    shape: integer or float (positive)
        the shape parameter; it relates to the sigma parameter: s = log(shape)

    scale: integer or float (positive)
        the scale parameter; it relates to the mean of log(x): m = log(scale)
    """

    s = log(shape)
    m = log(scale)

    return 1 / (x * s * sqrt(2 * pi)) * exp(-1 / 2. * ((log(x) - m)**2 / s**2))

# ============================================================================ #


texto = """
======================================================================================
Welcome to GrainSizeTools script v1.4.3
======================================================================================
GrainSizeTools is a free open-source cross-platform script to visualize and characterize
the grain size in polycrystalline materials from thin sections and estimate differential
stresses via paleopizometers.

METHODS AVAILABLE
==================  ==================================================================
Function            Description
==================  ==================================================================
extract_areas       Extract the areas of the grains from a text file (txt, csv or xlsx)
calc_diameters      Calculate the diameter via the equivalent circular diameter
find_grain_size     Estimate the apparent grain size and visualize their distribution
derive3D            Estimate the actual grain size distribution via steorology methods
quartz_piezometer   Estimate diff. stress from grain size using quartz piezometers
olivine_piezometer  Estimate diff. stress from grain size using olivine piezometers
other_pizometers    Estimate diff. stress from grain size using other piezometers
==================  ==================================================================

You can get information on the different methods by:
    (1) Typing help(name of the function in the console. e.g. >>> help(derive3D)
    (2) In the Spyder IDE by writing the name of the function and clicking Ctrl + I
    (3) Visit script documentation at https://marcoalopez.github.io/GrainSizeTools/


EXAMPLES
--------
Extracting data using the automatic mode:
>>> areas = extract_areas()

Estimate the equivalent circular diameters:
>>> diameters = calc_diameters(areas)

Estimate and visualize different apparent grain size measures
>>> find_grain_size(areas, diameters, plot='sqrt')

Estimate differential stress using piezometric relations
>>> quartz_piezometer(grain_size=5.7, piezometer='Stipp_Tullis')

Estimate the actual 3D grain size distribution from thin sections
>>> derive3D(diameters, numbins=15, set_limit=40)
>>> derive3D(diameters, numbins=15, set_limit=None, fit=True)
"""
print(texto)

if float(np.__version__[0:4]) < 1.11:
    print('The installed Numpy version', np.__version__, 'is too old.')
    print('Please upgrade to v1.11 or higher')

# ============================================================================ #
# Make it correct, make it clear, make it concise, make it fast. In that order.#
#                                                                     Wes Dyer #
# ============================================================================ #
